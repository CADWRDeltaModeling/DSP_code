
import pandas as pd
import numpy as np

import pyhecdss
from pydelmod.create_ann_inputs import get_dss_data

from vtools.functions.filter import cosine_lanczos

import datetime as dt
import os

import matplotlib.pyplot as plt

import re
import shutil

def minimize_flow(df, start, end, min_val):
    df.loc[start:end,] = [min(min_val, d) for d in df.loc[start:end,]]
    
    return df

def shift_subtide(df, shift_val):
    filt_df = cosine_lanczos(df.copy(),cutoff_period='40H', padtype='odd')
    shift_df = filt_df.copy()
    shift_df.index = shift_df.index + pd.Timedelta(days=shift_val)
    shift_df = shift_df.to_frame()
    shift_df.columns = ['shift_filter']

    shift_df['inst'] = df
    shift_df['eg_filter'] = filt_df

    shift_df['out'] = shift_df['inst'] - shift_df['eg_filter'] + shift_df['shift_filter']

    # plt.plot(shift_df.index.to_timestamp()[(shift_df.index.to_timestamp() >= '1994-01-01') & 
    #                                        (shift_df.index.to_timestamp() <= '1994-03-01')], 
    #                                        shift_df.values[(shift_df.index.to_timestamp() >= '1994-01-01') & 
    #                                                        (shift_df.index.to_timestamp() <= '1994-03-01')])


    
    return shift_df[['out']]

def write_out(df, out_dss_file, eg_dss_file, b_part, c_part, f_part, unit_part, ptype):
    
    with pyhecdss.DSSFile(eg_dss_file) as d_in:
        with pyhecdss.DSSFile(out_dss_file, create_new=True) as d_out:
            incat = d_in.read_catalog()  # all the pathnames in the DSS file
            paths_in = d_in.get_pathnames(incat)

            path_replace = paths_in[incat[(incat['B'] == b_part) & (incat['C'] == c_part)].index[0]]
            path_new = path_replace.rsplit("/", 2)[0] + "/" + f_part + "/"
            e_part = path_new.strip('/').split('/')[-2]

            # write the df into out_dss_file
            if e_part.startswith('IR-'):
                d_out.write_its(path_new, out_dss_file, unit_part, ptype)  # write to output DSS file
            else:
                # need to shift by one day because of DSS writing timestamp issues
                # df.index = df.index + pd.Timedelta(days=1)
                if df.index.freq is None:
                    df.index.freq = pd.infer_freq(df.index)
                # write regular output to DSS file
                d_out.write_rts(path_new, df, unit_part, ptype)


def write_out_remaining(out_dss_file, eg_dss_file, b_c_part, ptype):
    
    with pyhecdss.DSSFile(eg_dss_file) as d_in:
        with pyhecdss.DSSFile(out_dss_file) as d_out:
            incat = d_in.read_catalog()  # all the pathnames in the DSS file
            paths_in = d_in.get_pathnames(incat)

            paths_replaced = []
            for b_part, c_part in b_c_part:
                paths_replaced.append(paths_in[incat[(incat['B'] == b_part) & (incat['C'] == c_part)].index[0]])

            missing_paths = list(set(paths_in) - set(paths_replaced))

            for p in missing_paths:
                df = None
                units = None
                ptype = None
                # print(f'Writing out {p} units {units} pytype {ptype}')
                if d_in.parse_pathname_epart(p).startswith('IR-'):
                    df, units, ptype = d_in.read_its(p)
                    if units == 'und':
                        units = 'UNSPECIF'
                    # write to output DSS file
                    d_out.write_its(p, df, units, ptype)
                else:
                    df, units, ptype = d_in.read_rts(p)
                    if units == 'und':
                        units = 'UNSPECIF'
                    # write to output DSS file
                    d_out.write_rts(p, df, units, ptype)

def update_config(infile, case_in, case_out, mods):
    
    with open(infile.format(case=case_in), 'r') as c_in:
        content = c_in.readlines()

        # Replace the line that starts with 'SAC_EXPERIMENT'
        new_content = []
        for line in content:
            if line.startswith("SAC_EXPERIMENT") and "SAC_EXPERIMENT" in mods:
                new_content.append(f"SAC_EXPERIMENT\t\t\t DSP_LHC_{case_out}\n") 
            elif line.startswith("DSM2MODIFIER") and "DSM2MODIFIER" in mods:
                new_content.append(f"DSM2MODIFIER             lhc_{case_out}\n")
            elif line.startswith("STAGE_EXPERIMENT") and "STAGE_EXPERIMENT" in mods:
                new_content.append(f"STAGE_EXPERIMENT         DSP_LHC_{case_out}\n")
            elif line.startswith('config_latinhypercube') and 'config_latinhypercube' in mods:
                new_content.append(f'config_latinhypercube_{case_out}.inp\n')
            elif line.startswith('EXPORT_EXPERIMENT') and 'EXPORT_EXPERIMENT' in mods:
                new_content.append(f'EXPORT_EXPERIMENT	     DSP_LHC_{case_out}\n')
            else:
                new_content.append(line)

        # Write the modified content back to the file            
        with open(infile.format(case=case_out), 'w') as c_out:
            c_out.writelines(new_content)

def copy_other_dss(dsm2_dir, case_in, case_out):
    shutil.copy(os.path.join(dsm2_dir,f'timeseries/lhc_{case_in}_gates.dss'), 
                os.path.join(dsm2_dir,f'timeseries/lhc_{case_out}_gates.dss'))
    shutil.copy(os.path.join(dsm2_dir,f'timeseries/lhc_{case_in}_dcd.dss'), 
                os.path.join(dsm2_dir,f'timeseries/lhc_{case_out}_dcd.dss'))

dsm2_dir = '../../model/dsm2/DSP_DSM2_202412/latinhypercube_v4'
case_hist_dss = os.path.join(dsm2_dir,'timeseries/lhc_{case}_hist.dss')
ec_dss = os.path.join(dsm2_dir,'timeseries/lhc_{case}_ec_est.dss')

config_file = os.path.join(dsm2_dir,'config_latinhypercube_{case}.inp')
hydro_file = os.path.join(dsm2_dir,'hydro_latinhypercube_{case}.inp')
qual_file = os.path.join(dsm2_dir,'qual_ec_latinhypercube_{case}.inp')
qual_x2_file = os.path.join(dsm2_dir,'qual_ec_latinhypercube_x2_{case}.inp')

os.chdir(os.path.dirname(os.path.abspath(__file__)))

# CASE 23 -> 101 ============================================================================================
case_in = 23
ec_ts_in = get_dss_data({'RSAC054':ec_dss.format(case=case_in)}, 'b_part', primary_part_c_part_dict={'RSAC054':'EC'}, 
                        primary_part_e_part_dict={'RSAC054':'15MIN'},daily_avg=False)

# minimize sac flow
case_out = 101
print(case_out)
start_min = pd.to_datetime('1993-11-1')
end_min = pd.to_datetime('1994-3-31')
min_val = 11000.
case_ts_in = get_dss_data({'RSAC155':case_hist_dss.format(case=case_in)}, 'b_part', daily_avg=False)
case_ts_in = pd.to_numeric(case_ts_in.iloc[:,0])

case_ts_out = minimize_flow(case_ts_in, start_min, end_min, min_val)
write_out(case_ts_out, case_hist_dss.format(case=case_out), case_hist_dss.format(case=case_in), 'RSAC155', 'FLOW', f'DSP_LHC_{case_out}', 'CFS', 'PER-AVER')
write_out(ec_ts_in, ec_dss.format(case=case_out), ec_dss.format(case=case_in), 'RSAC054', 'EC', f'DSP_LHC_{case_out}', "uS/CM", 'PER-AVER')
write_out_remaining(case_hist_dss.format(case=case_out), case_hist_dss.format(case=case_in), [('RSAC155', 'FLOW'),
                                                                                              ('RSAC054', 'EC')], 'PER-AVER')
update_config(config_file, case_in, case_out, ['SAC_EXPERIMENT','DSM2MODIFIER'])
update_config(hydro_file, case_in, case_out, ['config_latinhypercube'])
update_config(qual_file, case_in, case_out, ['config_latinhypercube'])
update_config(qual_x2_file, case_in, case_out, ['config_latinhypercube'])
copy_other_dss(dsm2_dir, case_in, case_out)

# CASE 23 -> 102 ============================================================================================
case_in = 23

# move subtide +7 days
case_out = 102
print(case_out)
case_ts_in = get_dss_data({'RSAC054':case_hist_dss.format(case=case_in)}, 'b_part', primary_part_c_part_dict={'RSAC054':'STAGE'}, daily_avg=False)
case_ts_in = pd.to_numeric(case_ts_in.iloc[:,0])

case_ts_out = shift_subtide(case_ts_in, 7)
write_out(case_ts_out, case_hist_dss.format(case=case_out), case_hist_dss.format(case=case_in), 'RSAC054', 'STAGE', f'DSP_LHC_{case_out}', 'FT', 'PER-AVER')

write_out(ec_ts_in, ec_dss.format(case=case_out), ec_dss.format(case=case_in), 'RSAC054', 'EC', f'DSP_LHC_{case_out}', "uS/CM", 'PER-AVER')
write_out_remaining(case_hist_dss.format(case=case_out), case_hist_dss.format(case=case_in), [('RSAC054', 'STAGE'),
                                                                                              ('RSAC054', 'EC')], 'PER-AVER')
update_config(config_file, case_in, case_out, ['STAGE_EXPERIMENT','DSM2MODIFIER'])
update_config(hydro_file, case_in, case_out, ['config_latinhypercube'])
update_config(qual_file, case_in, case_out, ['config_latinhypercube'])
update_config(qual_x2_file, case_in, case_out, ['config_latinhypercube'])
copy_other_dss(dsm2_dir, case_in, case_out)

# CASE 23 -> 103 ============================================================================================
case_in = 23

# move subtide -7 days
case_out = 103
print(case_out)
case_ts_in = get_dss_data({'RSAC054':case_hist_dss.format(case=case_in)}, 'b_part', primary_part_c_part_dict={'RSAC054':'STAGE'}, daily_avg=False)
case_ts_in = pd.to_numeric(case_ts_in.iloc[:,0])

case_ts_out = shift_subtide(case_ts_in, -7)
write_out(case_ts_out, case_hist_dss.format(case=case_out), case_hist_dss.format(case=case_in), 'RSAC054', 'STAGE', f'DSP_LHC_{case_out}', 'FT', 'PER-AVER')

write_out(ec_ts_in, ec_dss.format(case=case_out), ec_dss.format(case=case_in), 'RSAC054', 'EC', f'DSP_LHC_{case_out}', "uS/CM", 'PER-AVER')
write_out_remaining(case_hist_dss.format(case=case_out), case_hist_dss.format(case=case_in), [('RSAC054', 'STAGE'),
                                                                                              ('RSAC054', 'EC')], 'PER-AVER')
update_config(config_file, case_in, case_out, ['STAGE_EXPERIMENT','DSM2MODIFIER'])
update_config(hydro_file, case_in, case_out, ['config_latinhypercube'])
update_config(qual_file, case_in, case_out, ['config_latinhypercube'])
update_config(qual_x2_file, case_in, case_out, ['config_latinhypercube'])
copy_other_dss(dsm2_dir, case_in, case_out)

# CASE 23 -> 104 ============================================================================================
case_in = 23

# maintain high exports
case_out = 104
print(case_out)
case_ts_in = get_dss_data({'CHCCC006':case_hist_dss.format(case=case_in),
                           'CHDMC004':case_hist_dss.format(case=case_in),
                           'CHSWP003':case_hist_dss.format(case=case_in),
                           'CHVCT001':case_hist_dss.format(case=case_in),
                           'ROLD034':case_hist_dss.format(case=case_in)}, 
                           'b_part', 
                           primary_part_c_part_dict={'CHCCC006':'FLOW-DIVERSION',
                                                     'CHDMC004':'FLOW-EXPORT',
                                                     'CHSWP003':'FLOW-EXPORT',
                                                     'CHVCT001':'FLOW-EXPORT',
                                                     'ROLD034':'FLOW-EXPORT'}, daily_avg=False)
case_ts_in = case_ts_in.apply(pd.to_numeric, errors='coerce')

scale_in_ts = case_ts_in.copy()
scale_in_ts = scale_in_ts.apply(lambda x: x.div(x.sum()), axis=1)

case_ts_in['sum'] = case_ts_in.sum(axis=1)
start_exp = pd.to_datetime('1993-11-1')
end_exp = pd.to_datetime('1994-3-31')
case_ts_in.loc[start_exp:end_exp, 'sum'] = 10000

# Join the scaled dataframe with the modified input timeseries 
merge = pd.merge(case_ts_in['sum'],scale_in_ts, how='inner', left_index=True, right_index=True)
merge.iloc[:, 1:] =  merge.iloc[:, 1:].multiply(merge.iloc[:,0], axis='index') # distribute the modified timeseries across columns
merge.index = merge.index.to_timestamp()

write_out(merge['CHCCC006'], case_hist_dss.format(case=case_out), case_hist_dss.format(case=case_in), 
          'CHCCC006', 'FLOW-DIVERSION', f'DSP_LHC_{case_out}', 'CFS', 'PER-AVER')
write_out(merge['CHDMC004'], case_hist_dss.format(case=case_out), case_hist_dss.format(case=case_in), 
          'CHDMC004', 'FLOW-EXPORT', f'DSP_LHC_{case_out}', 'CFS', 'PER-AVER')
write_out(merge['CHSWP003'], case_hist_dss.format(case=case_out), case_hist_dss.format(case=case_in), 
          'CHSWP003', 'FLOW-EXPORT', f'DSP_LHC_{case_out}', 'CFS', 'PER-AVER')
write_out(merge['CHVCT001'], case_hist_dss.format(case=case_out), case_hist_dss.format(case=case_in), 
          'CHVCT001', 'FLOW-EXPORT', f'DSP_LHC_{case_out}', 'CFS', 'PER-AVER')
write_out(merge['ROLD034'], case_hist_dss.format(case=case_out), case_hist_dss.format(case=case_in), 
          'ROLD034', 'FLOW-EXPORT', f'DSP_LHC_{case_out}', 'CFS', 'PER-AVER')

write_out(ec_ts_in, ec_dss.format(case=case_out), ec_dss.format(case=case_in), 'RSAC054', 'EC', f'DSP_LHC_{case_out}', "uS/CM", 'PER-AVER')
write_out_remaining(case_hist_dss.format(case=case_out), case_hist_dss.format(case=case_in), [('CHCCC006', 'FLOW-DIVERSION'),
                                                                                              ('CHDMC004', 'FLOW-EXPORT'),
                                                                                              ('CHSWP003', 'FLOW-EXPORT'),
                                                                                              ('CHVCT001', 'FLOW-EXPORT'),
                                                                                              ('ROLD034', 'FLOW-EXPORT'),
                                                                                              ('RSAC054', 'EC')], 'PER-AVER')
update_config(config_file, case_in, case_out, ['EXPORT_EXPERIMENT','DSM2MODIFIER'])
update_config(hydro_file, case_in, case_out, ['config_latinhypercube'])
update_config(qual_file, case_in, case_out, ['config_latinhypercube'])
update_config(qual_x2_file, case_in, case_out, ['config_latinhypercube'])
copy_other_dss(dsm2_dir, case_in, case_out)

# CASE 45 -> 105 ============================================================================================
case_in = 45
ec_ts_in = get_dss_data({'RSAC054':ec_dss.format(case=case_in)}, 'b_part', primary_part_c_part_dict={'RSAC054':'EC'}, daily_avg=False)

# minimize sac flow
case_out = 105
print(case_out)
start_min = pd.to_datetime('2000-7-1')
end_min = pd.to_datetime('2001-3-31')
min_val = 11000.
case_ts_in = get_dss_data({'RSAC155':case_hist_dss.format(case=case_in)}, 'b_part', daily_avg=False)
case_ts_in = pd.to_numeric(case_ts_in.iloc[:,0])

case_ts_out = minimize_flow(case_ts_in, start_min, end_min, min_val)
write_out(case_ts_out, case_hist_dss.format(case=case_out), case_hist_dss.format(case=case_in), 'RSAC155', 'FLOW', f'DSP_LHC_{case_out}', 'CFS', 'PER-AVER')

write_out(ec_ts_in, ec_dss.format(case=case_out), ec_dss.format(case=case_in), 'RSAC054', 'EC', f'DSP_LHC_{case_out}', "uS/CM", 'PER-AVER')
write_out_remaining(case_hist_dss.format(case=case_out), case_hist_dss.format(case=case_in), [('RSAC155', 'FLOW'),
                                                                                              ('RSAC054', 'EC')], 'PER-AVER')
update_config(config_file, case_in, case_out, ['SAC_EXPERIMENT','DSM2MODIFIER'])
update_config(hydro_file, case_in, case_out, ['config_latinhypercube'])
update_config(qual_file, case_in, case_out, ['config_latinhypercube'])
update_config(qual_x2_file, case_in, case_out, ['config_latinhypercube'])
copy_other_dss(dsm2_dir, case_in, case_out)

# CASE 45 -> 106 ============================================================================================
case_in = 45

# move subtide +7 days
case_out = 106
print(case_out)
case_ts_in = get_dss_data({'RSAC054':case_hist_dss.format(case=case_in)}, 'b_part', primary_part_c_part_dict={'RSAC054':'STAGE'}, daily_avg=False)
case_ts_in = pd.to_numeric(case_ts_in.iloc[:,0])

case_ts_out = shift_subtide(case_ts_in, 7)
write_out(case_ts_out, case_hist_dss.format(case=case_out), case_hist_dss.format(case=case_in), 'RSAC054', 'STAGE', f'DSP_LHC_{case_out}', 'FT', 'PER-AVER')

write_out(ec_ts_in, ec_dss.format(case=case_out), ec_dss.format(case=case_in), 'RSAC054', 'EC', f'DSP_LHC_{case_out}', "uS/CM", 'PER-AVER')
write_out_remaining(case_hist_dss.format(case=case_out), case_hist_dss.format(case=case_in), [('RSAC054', 'STAGE'),
                                                                                              ('RSAC054', 'EC')], 'PER-AVER')
update_config(config_file, case_in, case_out, ['STAGE_EXPERIMENT','DSM2MODIFIER'])
update_config(hydro_file, case_in, case_out, ['config_latinhypercube'])
update_config(qual_file, case_in, case_out, ['config_latinhypercube'])
update_config(qual_x2_file, case_in, case_out, ['config_latinhypercube'])
copy_other_dss(dsm2_dir, case_in, case_out)

# CASE 45 -> 107 ============================================================================================
case_in = 45

# move subtide -7 days
case_out = 107
print(case_out)
case_ts_in = get_dss_data({'RSAC054':case_hist_dss.format(case=case_in)}, 'b_part', primary_part_c_part_dict={'RSAC054':'STAGE'}, daily_avg=False)
case_ts_in = pd.to_numeric(case_ts_in.iloc[:,0])

case_ts_out = shift_subtide(case_ts_in, -7)
write_out(case_ts_out, case_hist_dss.format(case=case_out), case_hist_dss.format(case=case_in), 'RSAC054', 'STAGE', f'DSP_LHC_{case_out}', 'FT', 'PER-AVER')

write_out(ec_ts_in, ec_dss.format(case=case_out), ec_dss.format(case=case_in), 'RSAC054', 'EC', f'DSP_LHC_{case_out}', "uS/CM", 'PER-AVER')
write_out_remaining(case_hist_dss.format(case=case_out), case_hist_dss.format(case=case_in), [('RSAC054', 'STAGE'),
                                                                                              ('RSAC054', 'EC')], 'PER-AVER')
update_config(config_file, case_in, case_out, ['STAGE_EXPERIMENT','DSM2MODIFIER'])
update_config(hydro_file, case_in, case_out, ['config_latinhypercube'])
update_config(qual_file, case_in, case_out, ['config_latinhypercube'])
update_config(qual_x2_file, case_in, case_out, ['config_latinhypercube'])
copy_other_dss(dsm2_dir, case_in, case_out)