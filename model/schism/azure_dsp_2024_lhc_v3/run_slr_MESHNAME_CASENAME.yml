resource_group: dwrbdo_dsp # the resource group containing the batch account
job_name: slr_{job_name}_{meshname}_{cname} # job name, will be used to name the pool and the job
batch_account_name: dwrbdodspbatch # batch account name
storage_account_name: dwrbdodspsa # this is the storage account containing batch and storage_container defined below
storage_container_name: test # this is mounted to $AZ_BATCH_MOUNTS_DIR/<<storage_container_name>> in addition to batch container which is mounted to $AZ_BATCH_MOUNTS_DIR/batch
study_copy_flags: --recursive --preserve-symlinks --exclude-regex "outputs.*/.*nc"
study_dir: {rel_study_dir} # where the relative study directory for the simulation will be
setup_dirs: # these are directories that are also copied in addition to the study_dir
  - atmos # try to avoid copying this and use symlink to mounted container instead (see mpi_command below)
num_hosts: 2 # number of nodes in the pool
# num_cores: <<number of cores total>> # is optional as default is number of cores per host * number of hosts
num_scribes: 10 # This is used in the mpi_cmd template if referred to there
# command to run , assume the study_dir is current directory
mpi_opts: --bind-to core
task_slots_per_node: 1
mpi_command: |
  cd sflux;
  rm -f *.nc;
  python make_links_az.py;
  cd ../;
  source dsp_slr_{meshname}_{cname}.clinic.sh;
  mpirun -np {num_cores} -f hostfile {mpi_opts} pschism_PREC_EVAP_GOTM_TVD-VL {num_scribes}
# template for the pool name, which is used to create the pool with appropriate settings
template_name: "alma87_mvapich2_20240426" # this is the template name for the pool, e.g. "centos7" or "alma8"
delete_after_mins: 600 # delete the job after this many minutes
