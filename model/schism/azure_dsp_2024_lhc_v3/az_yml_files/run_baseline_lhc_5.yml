resource_group: dwrbdo_dsp # the resource group containing the batch account
job_name: dsp_2024_baseline_lhc_5 # job name, will be used to name the pool and the job
batch_account_name: dwrbdodspbatch # batch account name
storage_account_name: dwrbdodspsa # this is the storage account containing batch and storage_container defined below
storage_container_name: test # this is mounted to $AZ_BATCH_MOUNTS_DIR/<<storage_container_name>> in addition to batch container which is mounted to $AZ_BATCH_MOUNTS_DIR/batch
study_copy_flags: --recursive --preserve-symlinks
study_dir: azure_dsp_2024_lhc_v3/simulations/baseline_lhc_5 # where the relative study directory for the simulation will be
setup_dirs: # these are directories that are also copied in addition to the study_dir
  - atmos # try to avoid copying this and use symlink to mounted container instead (see mpi_command below)
num_hosts: 2 # number of nodes in the pool
# num_cores: <<number of cores total>> # is optional as default is number of cores per host * number of hosts
num_scribes: 10 # This is used in the mpi_cmd template if referred to there
# command to run , assume the study_dir is current directory
mpi_opts: --bind-to core
mpi_command: "cd sflux;
rm -f *.nc;
python make_links_az.py;
cd ../;
source dsp_baseline_lhc_5.tropic.sh; 
mpirun -n {num_cores} --hostfile hostfile -x PATH -x LD_LIBRARY_PATH {mpi_opts} pschism_PREC_EVAP_GOTM_TVD-VL {num_scribes}; 
source dsp_baseline_lhc_5.clinic.sh; 
mpirun -n {num_cores} --hostfile hostfile -x PATH -x LD_LIBRARY_PATH {mpi_opts} pschism_PREC_EVAP_GOTM_TVD-VL {num_scribes}"
# template for the pool name, which is used to create the pool with appropriate settings
template_name: "alma87_20240426" # this is the template name for the pool, e.g. "centos7" or "alma8"
delete_after_mins: 2000 # delete the job after this many minutes
